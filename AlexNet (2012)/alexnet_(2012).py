# -*- coding: utf-8 -*-
"""AlexNet (2012).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15AxVm816FW27LvQo2SSU337LuMZJKY5x
"""

# Importing basic libs
import torch
import torch.nn as nn
from torch.nn import Module
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np

# User verification for device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f'Using {device}.')

class AlexNet(Module):
  """
    AlexNet (2012)
    3 x 224 x 224 input
    Novelties :
      ReLU (became a standard in DL)
      Local Response Normalization (LRN was later discarded by Simonyan et al.)
      Overlapping pooling
      GPU distribution (not implemented here)
      Dropout (became a standard in DL for CV)
  """
  def __init__(self):
    super(AlexNet, self).__init__()
    # Non-Linearity applied after every layer
    self.NL = nn.ReLU()
    # Regularization term to limit overfitting
    self.REG = nn.Dropout(p = 0.5)
    # LRN parameters
    self.k = 2
    self.n = 5
    self.alpha = 1e-4
    self.beta = 0.75
    # Feature extraction
    self.C1 = nn.Conv2d(3, 96, 11, 4) # 96 x 54 x 54 output
    self.LRN1 = nn.LocalResponseNorm(self.n, self.alpha, self.beta, self.k) # 96 x 54 x 54 output
    self.MAXPOOL1 = nn.MaxPool2d(3, 2) # 96 x 26 x 26 output
    self.C2 = nn.Conv2d(96, 256, 5) # 256 x 22 x 22 output
    self.LRN2 = nn.LocalResponseNorm(self.n, self.alpha, self.beta, self.k) # 256 x 22 x 22 output
    self.MAXPOOL2 = nn.MaxPool2d(3, 2) # 256 x 10 x 10 output
    self.C3 = nn.Conv2d(256, 384, 3, 1, 1) # 384 x 10 x 10 output
    self.C4 = nn.Conv2d(384, 384, 3, 1, 1) # 384 x 10 x 10 output
    self.C5 = nn.Conv2d(384, 256, 3, 1, 1) # 256 x 10 x 10 output
    self.MAXPOOL3 = nn.MaxPool2d(3, 2) # 256 x 4 x 4 output
    # Classification
    self.FC1 = nn.Linear(256 * 4 * 4, 4096) # 4096 x 1 output
    self.FC2 = nn.Linear(4096, 4096) # 4096 x 1 output
    self.FC3 = nn.Linear(4096, 2) # 10 x 1 output (1000 x 1 in original paper with 1000 classes)
    # Normalizing output
    self.OUT = nn.Softmax(dim = 1) # 10 x 1 output

  def forward(self, X):
    y = self.C1(X)
    y = self.NL(y)
    y = self.LRN1(y)
    y = self.MAXPOOL1(y)
    y = self.C2(y)
    y = self.NL(y)
    y = self.LRN2(y)
    y = self.MAXPOOL2(y)
    y = self.C3(y)
    y = self.NL(y)
    y = self.C4(y)
    y = self.NL(y)
    y = self.C5(y)
    y = self.NL(y)
    y = self.MAXPOOL3(y)
    y = torch.reshape(y, (y.shape[0], y.shape[1] * y.shape[2] * y.shape[3]))
    y = self.REG(y)
    y = self.FC1(y)
    y = self.NL(y)
    y = self.REG(y)
    y = self.FC2(y)
    y = self.NL(y)
    logits = self.FC3(y)
    y = self.NL(y)
    probs = self.OUT(logits)
    return probs

# Just a sanity check
X = torch.ones([32, 3, 224, 224])
net = AlexNet()
y = net(X)
print(y.shape)

# Commented out IPython magic to ensure Python compatibility.
# WARNING : ALEXNET IS A HUGE MODEL AND IS NOT MEANT TO BE TRAINED ON SMALL DATASETS
# THIS IS SIMPLY A SAMPLE TRAINING PLATFORM
# ALEXNET WILL SEVERELY OVERFIT ON SMALL DATASETS
import os
# %mkdir data
# %cd /content/data/
# %ls
!wget http://files.fast.ai/data/examples/dogscats.tgz
!tar -zxvf dogscats.tgz

data_dir = '/content/data/dogscats'

normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

imagenet_format = transforms.Compose([
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                normalize,
            ])

dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), imagenet_format)
         for x in ['train', 'valid']}

os.path.join(data_dir,'train')
dset_sizes = {x: len(dsets[x]) for x in ['train', 'valid']}

training_loader = DataLoader(dsets['train'], batch_size = 32, shuffle = True)
validation_loader = DataLoader(dsets['valid'], batch_size = 5, shuffle = False)

# Some sanity checks
def viz(image):
  image = image.numpy().transpose((1, 2, 0))
  plt.imshow(image)

for i, data in enumerate(training_loader):
  print("Checking training loader : ")
  batch, labels = data
  print(f'Batch shape : {batch.shape}')
  if i == 3:
    break
print("==================")
for i, data in enumerate(validation_loader):
  print("Checking validation loader : ")
  batch, labels = data
  print(f'Batch shape : {batch.shape} batch labels : {labels}')
  batch_viz = torchvision.utils.make_grid(batch)
  viz(batch_viz)
  if i == 3:
    break

# These are some default training parameters which are tested and indeed lead to learning
# but they could be improved
alexnet = AlexNet().to(device)
criterion = nn.CrossEntropyLoss()
lr = 0.001
optim = torch.optim.SGD(alexnet.parameters(),lr = lr)

# Defining single epoch training pass
def trainer(model, dataloader, criterion, optimizer):
  model.train()
  running_loss = 0.0

  for X, y_T in dataloader:
      optimizer.zero_grad()

      X = X.to(device)
      y_T = y_T.to(device)

      probs = model(X)   
      loss = criterion(probs, y_T)
      running_loss += loss.item() * X.size(0)

      loss.backward()
      optimizer.step()
  epoch_loss = running_loss / len(dataloader.dataset)
  return model, optimizer, epoch_loss

# Define single epoch testing pass
def tester(model, dataloader, criterion, optimizer):
  model.eval()
  running_loss = 0.0

  for X, y_T in dataloader:
      X = X.to(device)
      y_T = y_T.to(device)

      probs = model(X)
      loss = criterion(probs, y_T)
      running_loss += loss.item() * X.size(0)
  epoch_loss = running_loss / len(dataloader.dataset)
  return model, epoch_loss

# Custom function to compute accuracy
def compute_accuracy(model, dataloader):
    correct_preds = 0 
    n = 0
    
    with torch.no_grad():
        model.eval()
        for X, y_T in dataloader:

            X = X.to(device)
            y_T = y_T.to(device)

            probs = model(X)
            _, predictions = torch.max(probs, 1)

            n += y_T.size(0)
            correct_preds += (predictions == y_T).sum()

    return correct_preds.float() / n

# Defining model trainer
def training(model, training_loader, validation_loader, criterion, optimizer, epochs):
  train_losses = []
  train_acc =[]
  valid_losses = []
  valid_acc = []

  for epoch in range(epochs):
    print(f'\nEpoch {epoch} : ')
    print("===========")
    
    model, optimizer, training_loss = trainer(model, training_loader, criterion, optimizer)
    training_acc = compute_accuracy(model, training_loader)
    train_losses.append(training_loss)
    train_acc.append(training_acc)

    with torch.no_grad():
      model, valid_loss = tester(model, validation_loader, criterion, optimizer)
      validation_acc = compute_accuracy(model, validation_loader)
      valid_losses.append(valid_loss)
      valid_acc.append(validation_acc)

    print(f'Training loss : {training_loss}')
    print(f'Training acc : {training_acc}')
    print(f'Validation loss : {valid_loss}')
    print(f'Validation acc : {validation_acc}')

  train_losses = np.array(train_losses) 
  valid_losses = np.array(valid_losses)
  train_acc = np.array(train_acc)
  valid_acc = np.array(valid_acc)

  fig, ax = plt.subplots(figsize = (10, 5))
  ax.plot(train_losses, color='blue', label='Training loss')
  ax.plot(train_acc, color='green', label='Training accuracy') 
  ax.plot(valid_losses, color='red', label='Validation loss')
  ax.plot(valid_acc, color='black', label='Validation accuracy')
  
  ax.set(title="Loss evolution", 
            xlabel='Epoch',
            ylabel='Loss/Accuracy') 
  ax.legend()
  fig.show()

training(alexnet, training_loader, validation_loader, criterion, optim, 15)

