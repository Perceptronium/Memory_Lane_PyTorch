{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16 (2015).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRuoJCj20_D8"
      },
      "outputs": [],
      "source": [
        "# Importing basic libs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Module\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User verification for device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device}.')"
      ],
      "metadata": {
        "id": "wg5Ab6eF1Wap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(Module):\n",
        "  \"\"\"\n",
        "  VGG16 (2015)\n",
        "  This paper showed that deep convnets are better than wide convnets\n",
        "  3 x 224 x 224 input\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(VGG16, self).__init__()\n",
        "    # ReLU non-linearity after every hidden layer\n",
        "    self.NL = nn.ReLU()\n",
        "    # Conv kernels fixed to (3x3) with stride of 1, spatial padding to conserve resolution\n",
        "    self.C1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "    self.C2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "    # Subsampling performed by maxpooling with kernel (2x2) by stride 2\n",
        "    self.SS1 = nn.MaxPool2d(2, 2)\n",
        "    self.C3 = nn.Conv2d(64, 128, 3, 1 ,1)\n",
        "    self.C4 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "    self.SS2 = nn.MaxPool2d(2, 2)\n",
        "    self.C5 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "    self.C6 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "    self.C7 = nn.Conv2d(256, 256, 1)\n",
        "    self.SS3 = nn.MaxPool2d(2, 2)\n",
        "    self.C8 = nn.Conv2d(256, 512, 3, 1, 1)\n",
        "    self.C9 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "    self.C10 = nn.Conv2d(512, 512, 1)\n",
        "    self.SS4 = nn.MaxPool2d(2, 2)\n",
        "    self.C11 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "    self.C12 = nn.Conv2d(512, 512, 3, 1, 1)\n",
        "    self.C13 = nn.Conv2d(512, 512, 1)\n",
        "    self.SS5 = nn.MaxPool2d(2, 2)\n",
        "    self.FC1 = nn.Linear(512 * 7 * 7, 4096)\n",
        "    self.FC2 = nn.Linear(4096, 4096)\n",
        "    self.FC3 = nn.Linear(4096, 2) #1000 in original paper\n",
        "    self.OUT = nn.Softmax(dim = 1)\n",
        "  def forward(self, X):\n",
        "    y = self.C1(X)\n",
        "    y = self.NL(y)\n",
        "    y = self.C2(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.SS1(y)\n",
        "    y = self.C3(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.C4(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.SS2(y)\n",
        "    y = self.C5(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.C6(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.C7(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.SS3(y)\n",
        "    y = self.C8(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.C9(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.C10(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.SS4(y)\n",
        "    y = self.C11(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.C12(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.C13(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.SS5(y)\n",
        "    y = torch.reshape(y, (y.shape[0], y.shape[1] * y.shape[2] * y.shape[3]))\n",
        "    y = self.FC1(y)\n",
        "    y = self.NL(y)\n",
        "    y = self.FC2(y)\n",
        "    y = self.NL(y)\n",
        "    logits = self.FC3(y)\n",
        "    probs = self.OUT(logits)\n",
        "    return probs"
      ],
      "metadata": {
        "id": "InrNsW4Y1bc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just a sanity check\n",
        "X = torch.ones([32, 3, 224, 224])\n",
        "net = VGG16()\n",
        "y = net(X)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "UQ4SrK7_4W1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WARNING : VGG16 IS A HUGE MODEL AND IS NOT MEANT TO BE TRAINED ON SMALL DATASETS\n",
        "# THIS IS SIMPLY A SAMPLE TRAINING PLATFORM\n",
        "# VGG16 WILL SEVERELY OVERFIT ON SMALL DATASETS\n",
        "import os\n",
        "%mkdir data\n",
        "%cd /content/data/\n",
        "!wget http://files.fast.ai/data/examples/dogscats.tgz\n",
        "!tar -zxvf dogscats.tgz\n"
      ],
      "metadata": {
        "id": "jPo4fbgu4aYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/data/dogscats'\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "imagenet_format = transforms.Compose([\n",
        "                transforms.CenterCrop(224),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "\n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), imagenet_format)\n",
        "         for x in ['train', 'valid']}\n",
        "\n",
        "os.path.join(data_dir,'train')\n",
        "dset_sizes = {x: len(dsets[x]) for x in ['train', 'valid']}\n",
        "\n",
        "training_loader = DataLoader(dsets['train'], batch_size = 32, shuffle = True)\n",
        "validation_loader = DataLoader(dsets['valid'], batch_size = 5, shuffle = False)"
      ],
      "metadata": {
        "id": "yJKojPSg4_zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Some sanity checks\n",
        "def viz(image):\n",
        "  image = image.numpy().transpose((1, 2, 0))\n",
        "  plt.imshow(image)\n",
        "\n",
        "for i, data in enumerate(training_loader):\n",
        "  print(\"Checking training loader : \")\n",
        "  batch, labels = data\n",
        "  print(f'Batch shape : {batch.shape}')\n",
        "  if i == 3:\n",
        "    break\n",
        "print(\"==================\")\n",
        "for i, data in enumerate(validation_loader):\n",
        "  print(\"Checking validation loader : \")\n",
        "  batch, labels = data\n",
        "  print(f'Batch shape : {batch.shape} batch labels : {labels}')\n",
        "  batch_viz = torchvision.utils.make_grid(batch)\n",
        "  viz(batch_viz)\n",
        "  if i == 3:\n",
        "    break\n",
        "\n",
        "# These are some default training parameters which are tested and indeed lead to learning\n",
        "# but they could be improved\n",
        "vgg = VGG16().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "optim = torch.optim.SGD(vgg.parameters(),lr = lr)\n",
        "\n",
        "# Defining single epoch training pass\n",
        "def trainer(model, dataloader, criterion, optimizer):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for X, y_T in dataloader:\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      X = X.to(device)\n",
        "      y_T = y_T.to(device)\n",
        "\n",
        "      probs = model(X)   \n",
        "      loss = criterion(probs, y_T)\n",
        "      running_loss += loss.item() * X.size(0)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  epoch_loss = running_loss / len(dataloader.dataset)\n",
        "  return model, optimizer, epoch_loss\n",
        "\n",
        "# Define single epoch testing pass\n",
        "def tester(model, dataloader, criterion, optimizer):\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for X, y_T in dataloader:\n",
        "      X = X.to(device)\n",
        "      y_T = y_T.to(device)\n",
        "\n",
        "      probs = model(X)\n",
        "      loss = criterion(probs, y_T)\n",
        "      running_loss += loss.item() * X.size(0)\n",
        "  epoch_loss = running_loss / len(dataloader.dataset)\n",
        "  return model, epoch_loss\n",
        "\n",
        "# Custom function to compute accuracy\n",
        "def compute_accuracy(model, dataloader):\n",
        "    correct_preds = 0 \n",
        "    n = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for X, y_T in dataloader:\n",
        "\n",
        "            X = X.to(device)\n",
        "            y_T = y_T.to(device)\n",
        "\n",
        "            probs = model(X)\n",
        "            _, predictions = torch.max(probs, 1)\n",
        "\n",
        "            n += y_T.size(0)\n",
        "            correct_preds += (predictions == y_T).sum()\n",
        "\n",
        "    return correct_preds.float() / n\n",
        "\n",
        "# Defining model trainer\n",
        "def training(model, training_loader, validation_loader, criterion, optimizer, epochs):\n",
        "  train_losses = []\n",
        "  train_acc =[]\n",
        "  valid_losses = []\n",
        "  valid_acc = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print(f'\\nEpoch {epoch} : ')\n",
        "    print(\"===========\")\n",
        "    \n",
        "    model, optimizer, training_loss = trainer(model, training_loader, criterion, optimizer)\n",
        "    training_acc = compute_accuracy(model, training_loader)\n",
        "    train_losses.append(training_loss)\n",
        "    train_acc.append(training_acc)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      model, valid_loss = tester(model, validation_loader, criterion, optimizer)\n",
        "      validation_acc = compute_accuracy(model, validation_loader)\n",
        "      valid_losses.append(valid_loss)\n",
        "      valid_acc.append(validation_acc)\n",
        "\n",
        "    print(f'Training loss : {training_loss}')\n",
        "    print(f'Training acc : {training_acc}')\n",
        "    print(f'Validation loss : {valid_loss}')\n",
        "    print(f'Validation acc : {validation_acc}')\n",
        "\n",
        "  train_losses = np.array(train_losses) \n",
        "  valid_losses = np.array(valid_losses)\n",
        "  train_acc = np.array(train_acc)\n",
        "  valid_acc = np.array(valid_acc)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize = (10, 5))\n",
        "  ax.plot(train_losses, color='blue', label='Training loss')\n",
        "  ax.plot(train_acc, color='green', label='Training accuracy') \n",
        "  ax.plot(valid_losses, color='red', label='Validation loss')\n",
        "  ax.plot(valid_acc, color='black', label='Validation accuracy')\n",
        "  \n",
        "  ax.set(title=\"Loss evolution\", \n",
        "            xlabel='Epoch',\n",
        "            ylabel='Loss/Accuracy') \n",
        "  ax.legend()\n",
        "  fig.show()\n",
        "\n",
        "training(vgg, training_loader, validation_loader, criterion, optim, 15)"
      ],
      "metadata": {
        "id": "tuET4OxI5Ail"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_BoP9yc15moT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}